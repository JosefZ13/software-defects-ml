{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4790971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All datasets loaded, scaled, split, and SMOTE-balanced (without warnings)!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ðŸ“¢ Ignore only harmless CPU warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Could not find the number of physical cores')\n",
    "\n",
    "# ðŸ“‚ Load datasets\n",
    "df_jm1 = pd.read_csv('../data/JM1.csv')\n",
    "df_kc1 = pd.read_csv('../data/KC1.csv')\n",
    "\n",
    "# ðŸ“‹ Prepare datasets\n",
    "\n",
    "# Prepare JM1\n",
    "df_jm1['defects'] = df_jm1['defects'].astype(int)\n",
    "X_jm1 = df_jm1.drop('defects', axis=1)\n",
    "y_jm1 = df_jm1['defects']\n",
    "\n",
    "scaler_jm1 = StandardScaler()\n",
    "X_scaled_jm1 = scaler_jm1.fit_transform(X_jm1)\n",
    "\n",
    "X_train_jm1, X_test_jm1, y_train_jm1, y_test_jm1 = train_test_split(\n",
    "    X_scaled_jm1, y_jm1, test_size=0.2, stratify=y_jm1, random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote_jm1, y_train_smote_jm1 = smote.fit_resample(X_train_jm1, y_train_jm1)\n",
    "\n",
    "# Prepare KC1\n",
    "df_kc1['defects'] = df_kc1['defects'].astype(int)\n",
    "X_kc1 = df_kc1.drop('defects', axis=1)\n",
    "y_kc1 = df_kc1['defects']\n",
    "\n",
    "scaler_kc1 = StandardScaler()\n",
    "X_scaled_kc1 = scaler_kc1.fit_transform(X_kc1)\n",
    "\n",
    "X_train_kc1, X_test_kc1, y_train_kc1, y_test_kc1 = train_test_split(\n",
    "    X_scaled_kc1, y_kc1, test_size=0.2, stratify=y_kc1, random_state=42\n",
    ")\n",
    "\n",
    "X_train_smote_kc1, y_train_smote_kc1 = smote.fit_resample(X_train_kc1, y_train_kc1)\n",
    "\n",
    "print(\"âœ… All datasets loaded, scaled, split, and SMOTE-balanced (without warnings)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67984fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Random Forest parameters for JM1: {'max_depth': 30, 'n_estimators': 300}\n",
      "Best F1 score from tuning: 0.9067\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf_jm1 = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Create model\n",
    "rf_jm1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search_rf_jm1 = GridSearchCV(estimator=rf_jm1, param_grid=param_grid_rf_jm1, \n",
    "                                  scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_rf_jm1.fit(X_train_smote_jm1, y_train_smote_jm1)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Random Forest parameters for JM1: {grid_search_rf_jm1.best_params_}\")\n",
    "print(f\"Best F1 score from tuning: {grid_search_rf_jm1.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8989668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Random Forest parameters for KC1: {'max_depth': 20, 'n_estimators': 300}\n",
      "Best F1 score from tuning: 0.9071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Create model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, \n",
    "                              scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_rf.fit(X_train_smote_kc1, y_train_smote_kc1)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Random Forest parameters for KC1: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best F1 score from tuning: {grid_search_rf.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce28adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best ANN parameters for JM1: {'activation': 'tanh', 'hidden_layer_sizes': (150, 100, 50)}\n",
      "Best F1 score from tuning: 0.8821\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for ANN\n",
    "param_grid_ann_jm1 = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "# Create model\n",
    "ann_jm1 = MLPClassifier(max_iter=500, random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search_ann_jm1 = GridSearchCV(estimator=ann_jm1, param_grid=param_grid_ann_jm1, \n",
    "                                   scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_ann_jm1.fit(X_train_smote_jm1, y_train_smote_jm1)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best ANN parameters for JM1: {grid_search_ann_jm1.best_params_}\")\n",
    "print(f\"Best F1 score from tuning: {grid_search_ann_jm1.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b667759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best ANN parameters for KC1: {'activation': 'relu', 'hidden_layer_sizes': (150, 100, 50)}\n",
      "Best F1 score from tuning: 0.8947\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for ANN\n",
    "param_grid_ann = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "# Create model\n",
    "ann = MLPClassifier(max_iter=500, random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search_ann = GridSearchCV(estimator=ann, param_grid=param_grid_ann, \n",
    "                               scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_ann.fit(X_train_smote_kc1, y_train_smote_kc1)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best ANN parameters for KC1: {grid_search_ann.best_params_}\")\n",
    "print(f\"Best F1 score from tuning: {grid_search_ann.best_score_:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
