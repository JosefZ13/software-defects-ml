{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06291956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "datasets = {\n",
    "    \"JM1\": \"../data/jm1.csv\",\n",
    "    \"KC1\": \"../data/kc1.csv\",\n",
    "    \"KC2\": \"../data/kc2.csv\",\n",
    "    \"PC1\": \"../data/pc1.csv\",\n",
    "    \"CM1\": \"../data/cm1.csv\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "def run_pipeline(dataset_name, path):\n",
    "    print(f\"\\nüìÅ === Processing {dataset_name} ===\")\n",
    "    df = pd.read_csv(path)\n",
    "    target_col = 'problems' if dataset_name == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "    rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "    ann = MLPClassifier(max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "    sm = SMOTE()\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    rf_sm = RandomForestClassifier().fit(X_train_sm, y_train_sm)\n",
    "    xgb_sm = XGBClassifier(use_label_encoder=False, eval_metric='logloss').fit(X_train_sm, y_train_sm)\n",
    "    ann_sm = MLPClassifier(max_iter=500).fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    models = {\n",
    "        'Logistic Regression': lr,\n",
    "        'Random Forest (No SMOTE)': rf,\n",
    "        'ANN (No SMOTE)': ann,\n",
    "        'Random Forest (SMOTE)': rf_sm,\n",
    "        'XGBoost (SMOTE)': xgb_sm,\n",
    "        'ANN (SMOTE)': ann_sm\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        all_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-score': f1_score(y_test, y_pred)\n",
    "        })\n",
    "for ds_name, ds_path in datasets.items():\n",
    "    run_pipeline(ds_name, ds_path)\n",
    "\n",
    "df_all_results = pd.DataFrame(all_results)\n",
    "df_all_results['SMOTE'] = df_all_results['Model'].apply(lambda x: 'SMOTE' in x)\n",
    "display(df_all_results.round(3))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "    df_no = df_all_results[df_all_results['SMOTE'] == False]\n",
    "    df_smote = df_all_results[df_all_results['SMOTE'] == True]\n",
    "\n",
    "    sns.barplot(data=df_no, x='Dataset', y=metric, hue='Model', ax=axes[0])\n",
    "    axes[0].set_title(f'{metric} f√∂re SMOTE')\n",
    "    axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "    sns.barplot(data=df_smote, x='Dataset', y=metric, hue='Model', ax=axes[1])\n",
    "    axes[1].set_title(f'{metric} efter SMOTE')\n",
    "    axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "    axes[0].legend(title='Modell')\n",
    "    axes[1].legend(title='Modell')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "for dataset in df_all_results['Dataset'].unique():\n",
    "    print(f\"\\nüìä ROC-kurvor f√∂r dataset: {dataset}\")\n",
    "    df = pd.read_csv(datasets[dataset])\n",
    "    target_col = 'problems' if dataset == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    X_train_sm, y_train_sm = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier().fit(X_train_sm, y_train_sm),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss').fit(X_train_sm, y_train_sm),\n",
    "        'ANN': MLPClassifier(max_iter=500).fit(X_train_sm, y_train_sm)\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_scores = model.decision_function(X_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Slump (AUC = 0.5)')\n",
    "    plt.title(f'ROC-kurvor ‚Äì {dataset}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "auc_scores = []\n",
    "\n",
    "for row in all_results:\n",
    "    dataset = row['Dataset']\n",
    "    model_name = row['Model']\n",
    "    df = pd.read_csv(datasets[dataset])\n",
    "    target_col = 'problems' if dataset == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if 'SMOTE' in model_name:\n",
    "        X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "    if 'Logistic Regression' in model_name:\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif 'Random Forest' in model_name:\n",
    "        model = RandomForestClassifier()\n",
    "    elif 'XGBoost' in model_name:\n",
    "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    elif 'ANN' in model_name:\n",
    "        model = MLPClassifier(max_iter=500)\n",
    "    else:\n",
    "        auc_scores.append(None)\n",
    "        continue\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_scores = model.decision_function(X_test)\n",
    "\n",
    "    auc_scores.append(roc_auc_score(y_test, y_scores))\n",
    "\n",
    "df_all_results['AUC'] = auc_scores\n",
    "display(df_all_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4dbeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "datasets = {\n",
    "    \"JM1\": \"../data/jm1.csv\",\n",
    "    \"KC1\": \"../data/kc1.csv\",\n",
    "    \"KC2\": \"../data/kc2.csv\",\n",
    "    \"PC1\": \"../data/pc1.csv\",\n",
    "    \"CM1\": \"../data/cm1.csv\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "def run_pipeline(dataset_name, path):\n",
    "    print(f\"\\nüìÅ Processing {dataset_name}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    target_col = 'problems' if dataset_name == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Modelltyper\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"ANN\": MLPClassifier(max_iter=500),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "\n",
    "    # Utan SMOTE\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) if hasattr(model, \"predict_proba\") else None\n",
    "        all_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': f\"{name} (No SMOTE)\",\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-score': f1_score(y_test, y_pred),\n",
    "            'AUC': auc,\n",
    "            'SMOTE': False\n",
    "        })\n",
    "\n",
    "    # Med SMOTE\n",
    "    X_train_sm, y_train_sm = SMOTE().fit_resample(X_train, y_train)\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_sm, y_train_sm)\n",
    "        y_pred = model.predict(X_test)\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) if hasattr(model, \"predict_proba\") else None\n",
    "        all_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': f\"{name} (SMOTE)\",\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-score': f1_score(y_test, y_pred),\n",
    "            'AUC': auc,\n",
    "            'SMOTE': True\n",
    "        })\n",
    "for ds_name, ds_path in datasets.items():\n",
    "    run_pipeline(ds_name, ds_path)\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(\"all_model_results_with_and_without_smote.csv\", index=False)\n",
    "display(df_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1955cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "datasets = {\n",
    "    \"JM1\": \"../data/jm1.csv\",\n",
    "    \"KC1\": \"../data/kc1.csv\",\n",
    "    \"KC2\": \"../data/kc2.csv\",\n",
    "    \"PC1\": \"../data/pc1.csv\",\n",
    "    \"CM1\": \"../data/cm1.csv\"\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "def run_pipeline(dataset_name, path):\n",
    "    print(f\"\\nüìÅ Processing {dataset_name}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    target_col = 'problems' if dataset_name == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"ANN\": MLPClassifier(max_iter=500),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "\n",
    "    # Utan SMOTE\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        auc_val = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) if hasattr(model, \"predict_proba\") else None\n",
    "        all_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': f\"{name} (No SMOTE)\",\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-score': f1_score(y_test, y_pred),\n",
    "            'AUC': auc_val,\n",
    "            'SMOTE': False\n",
    "        })\n",
    "\n",
    "    # Med SMOTE\n",
    "    X_train_sm, y_train_sm = SMOTE().fit_resample(X_train, y_train)\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_sm, y_train_sm)\n",
    "        y_pred = model.predict(X_test)\n",
    "        auc_val = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) if hasattr(model, \"predict_proba\") else None\n",
    "        all_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': f\"{name} (SMOTE)\",\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-score': f1_score(y_test, y_pred),\n",
    "            'AUC': auc_val,\n",
    "            'SMOTE': True\n",
    "        })\n",
    "for ds_name, ds_path in datasets.items():\n",
    "    run_pipeline(ds_name, ds_path)\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(\"all_model_results_with_and_without_smote.csv\", index=False)\n",
    "display(df_results.round(3))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "    df_no = df_results[df_results['SMOTE'] == False]\n",
    "    df_smote = df_results[df_results['SMOTE'] == True]\n",
    "\n",
    "    sns.barplot(data=df_no, x='Dataset', y=metric, hue='Model', ax=axes[0])\n",
    "    axes[0].set_title(f'{metric} ‚Äì Before SMOTE')\n",
    "    axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "    sns.barplot(data=df_smote, x='Dataset', y=metric, hue='Model', ax=axes[1])\n",
    "    axes[1].set_title(f'{metric} ‚Äì After SMOTE')\n",
    "    axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "    axes[0].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "for dataset in df_results['Dataset'].unique():\n",
    "    print(f\"\\nüìä ROC Curves ‚Äì {dataset}\")\n",
    "    df = pd.read_csv(datasets[dataset])\n",
    "    target_col = 'problems' if dataset == 'KC2' else 'defects'\n",
    "    if df[target_col].dtype == object:\n",
    "        df[target_col] = df[target_col].str.lower().map({'yes': 1, 'no': 0})\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    X_train_sm, y_train_sm = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'ANN': MLPClassifier(max_iter=500),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000)\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_sm, y_train_sm)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_scores = model.decision_function(X_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "    plt.title(f'ROC Curves ‚Äì {dataset}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
